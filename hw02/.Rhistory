lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[2:145]
tuning_sigma = lr.para[146]
tuning_pred = lr.para[147:446]
tuning_pred[1:9]
tuning = data.frame(tuning_pred, tuning_y)
cor_table = round(cor(tuning, use = "complete.obs"), 5)
cor_table
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_tuning,
nrow_test = nrow(processed_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[2:145]
tuning_sigma = lr.para[146]
tuning_pred = lr.para[147:446]
tuning_pred[1:9]
tuning = data.frame(tuning_pred, tuning_y)
cor_table = round(cor(tuning, use = "complete.obs"), 5)
cor_table
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_tuning,
nrow_test = nrow(processed_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[2:145]
tuning_sigma = lr.para[146]
tuning_pred = lr.para[147:446]
tuning_pred[1:9]
tuning = data.frame(tuning_pred, tuning_y)
cor_table = round(cor(tuning, use = "complete.obs"), 5)
cor_table
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_tuning,
nrow_test = nrow(processed_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[2:145]
tuning_sigma = lr.para[146]
tuning_pred = lr.para[147:446]
tuning_pred[1:9]
tuning = data.frame(tuning_pred, tuning_y)
cor_table = round(cor(tuning, use = "complete.obs"), 5)
cor_table
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_tuning,
nrow_test = nrow(processed_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[2:145]
tuning_sigma = lr.para[146]
tuning_pred = lr.para[147:446]
tuning_pred[1:9]
tuning = data.frame(tuning_pred, tuning_y)
cor_table = round(cor(tuning, use = "complete.obs"), 5)
cor_table
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_test,
nrow_test = nrow(processed_x_test))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
beta_list = lr.para[2:145]
ans_pred = lr.para[147:1146]
ans_pred[1:18]
ans_pred = data.frame(ans_pred)
colnames(ans_pred) = c("y")
rownames(ans_pred) = c()
ans_pred
sub_data = read.csv(file = 'test.csv')[1]
sub_data = cbind(sub_data, ans_pred)
write.csv(sub_data,"test_sub.csv", row.names = FALSE)
#suppressMessages function to load libraries siliently
suppressMessages(library(plyr))
suppressMessages(library(rethinking))
suppressMessages(library(rstan))
suppressMessages(library(tidyverse))
suppressMessages(library(ggplot2))
suppressMessages(library(gridExtra))
suppressMessages(library(caret))
all_train_data = read.csv(file = 'train.csv')
test_data = read.csv(file = 'test.csv')
train_y = all_train_data["y"] ## take out the y column
train_x = all_train_data[ , (names(all_train_data)!="y")]
fold_train_x = train_x[2:9]
unfold_train_x = train_x[10:length(train_x)]
fold_test_data = test_data[2:9]
unfold_test_data = test_data[10:length(test_data)]
fold_all_data = rbind(fold_train_x, fold_test_data)
unfold_all_data = rbind(unfold_train_x, unfold_test_data)
df_to_plot = cbind(fold_train_x, train_y)
pic1 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X0), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
pic2 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X1), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
grid.arrange(pic1, pic2, ncol=2)
pic1 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X2), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
pic2 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X3), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
grid.arrange(pic1, pic2, ncol=2)
pic1 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X4), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
pic2 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X5), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
grid.arrange(pic1, pic2, ncol=2)
pic1 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X6), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
pic2 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X8), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
grid.arrange(pic1, pic2, ncol=2)
unlink('hw2_report_cache', recursive = TRUE)
#suppressMessages function to load libraries siliently
suppressMessages(library(plyr))
suppressMessages(library(rethinking))
suppressMessages(library(rstan))
suppressMessages(library(tidyverse))
suppressMessages(library(ggplot2))
suppressMessages(library(gridExtra))
suppressMessages(library(caret))
all_train_data = read.csv(file = 'train.csv')
test_data = read.csv(file = 'test.csv')
train_y = all_train_data["y"] ## take out the y column
train_x = all_train_data[ , (names(all_train_data)!="y")]
fold_train_x = train_x[2:9]
unfold_train_x = train_x[10:length(train_x)]
fold_test_data = test_data[2:9]
unfold_test_data = test_data[10:length(test_data)]
fold_all_data = rbind(fold_train_x, fold_test_data)
unfold_all_data = rbind(unfold_train_x, unfold_test_data)
df_to_plot = cbind(fold_train_x, train_y)
pic1 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X0), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
pic2 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X1), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
grid.arrange(pic1, pic2, ncol=2)
pic1 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X2), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
pic2 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X3), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
grid.arrange(pic1, pic2, ncol=2)
pic1 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X4), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
pic2 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X5), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
grid.arrange(pic1, pic2, ncol=2)
pic1 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X6), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
pic2 = df_to_plot %>%
ggplot(aes(x=reorder(factor(X8), y), y = y))+
stat_summary(fun = "mean", geom = "bar")
grid.arrange(pic1, pic2, ncol=2)
drops = c("X3", "X4", "X6", "X8")
selected_fold_all_data = fold_all_data[ , !(names(fold_all_data) %in% drops)] # drop the unneed columns
selected_fold_all_data
special_cate = c("u", "x", "h", "g", "f")
levels(selected_fold_all_data$X5) = c(levels(selected_fold_all_data$X5), "new")
selected_fold_all_data$X5[! selected_fold_all_data$X5 %in% special_cate ] = "new" ## replace the categories
selected_fold_all_data = droplevels(selected_fold_all_data)  ## drop the levels which aren't used
selected_fold_all_data
dummies = dummyVars(~ ., data = selected_fold_all_data) ## function to one-hot encode
onehot_fold_all_data = data.frame(predict(dummies, newdata = selected_fold_all_data))
onehot_fold_all_data
#split all data to three parts, and combine the onehot_fold_all_data and unfold_all_data
processed_x_tuning = cbind(onehot_fold_all_data[1:300,], unfold_all_data[1:300,])
processed_x_train = cbind(onehot_fold_all_data[301:3209,], unfold_all_data[301:3209,])
processed_x_test = cbind(onehot_fold_all_data[3210:4209,], unfold_all_data[3210:4209,])
all_processed_x = rbind(processed_x_tuning, processed_x_train)
all_processed_x = rbind(all_processed_x, processed_x_test)
nzv = nearZeroVar(all_processed_x) # this function is to find out the column of which variance is 0
processed_x_tuning = processed_x_tuning[, -nzv]
processed_x_train = processed_x_train[, -nzv]
processed_x_test = processed_x_test[, -nzv]
tuning_y = as.vector(t(train_y))[1:300] # The tuning y
train_y = as.vector(t(train_y))[301:3209] # The training y
lr.model = "
data{
int<lower=0> nrow;
int<lower=0> ncol;
matrix[nrow, ncol] train_x; //use matirx rather than vector
vector[nrow] train_y;
int<lower=0> nrow_test;
matrix[nrow_test, ncol] test;
}
parameters{
real alpha;
vector[ncol] beta;
real<lower=0> sigma;
}
model{
alpha ~ normal(0,5);
beta ~ normal(0,9);
sigma ~ normal(0,2);
train_y ~ normal(train_x * beta + alpha, sigma);
//train_x lies afore beta, because it's a matrix multiplication
}
generated quantities{
real y_pred[nrow_test];
vector[nrow_test] mu;
mu = alpha + test * beta;
y_pred = normal_rng(mu, sigma); //get pred
}
"
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_tuning,
nrow_test = nrow(processed_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing( # optimizing function to accelerate the model
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[2:145]
tuning_sigma = lr.para[146]
tuning_pred = lr.para[147:446]
tuning_pred[1:9]
tuning = data.frame(tuning_pred, tuning_y)
cor_table = round(cor(tuning, use = "complete.obs"), 5) # to see the performence of model
cor_table
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_tuning,
nrow_test = nrow(processed_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing( # optimizing function to accelerate the model
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[2:145]
tuning_sigma = lr.para[146]
tuning_pred = lr.para[147:446]
tuning_pred[1:9]
tuning = data.frame(tuning_pred, tuning_y)
cor_table = round(cor(tuning, use = "complete.obs"), 5) # to see the performence of model
cor_table
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_tuning,
nrow_test = nrow(processed_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing( # optimizing function to accelerate the model
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[2:145]
tuning_sigma = lr.para[146]
tuning_pred = lr.para[147:446]
tuning_pred[1:9]
tuning = data.frame(tuning_pred, tuning_y)
cor_table = round(cor(tuning, use = "complete.obs"), 5) # to see the performence of model
cor_table
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_tuning,
nrow_test = nrow(processed_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing( # optimizing function to accelerate the model
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[2:145]
tuning_sigma = lr.para[146]
tuning_pred = lr.para[147:446]
tuning_pred[1:9]
tuning = data.frame(tuning_pred, tuning_y)
cor_table = round(cor(tuning, use = "complete.obs"), 5) # to see the performence of model
cor_table
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_tuning,
nrow_test = nrow(processed_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing( # optimizing function to accelerate the model
stan_m,
data = lr.data,
hessian = TRUE)
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_tuning,
nrow_test = nrow(processed_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing( # optimizing function to accelerate the model
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[2:145]
tuning_sigma = lr.para[146]
tuning_pred = lr.para[147:446]
tuning_pred[1:9]
tuning = data.frame(tuning_pred, tuning_y)
cor_table = round(cor(tuning, use = "complete.obs"), 5) # to see the performence of model
cor_table
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_tuning,
nrow_test = nrow(processed_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing( # optimizing function to accelerate the model
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[2:145]
tuning_sigma = lr.para[146]
tuning_pred = lr.para[147:446]
tuning_pred[1:9]
tuning = data.frame(tuning_pred, tuning_y)
cor_table = round(cor(tuning, use = "complete.obs"), 5) # to see the performence of model
cor_table
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_tuning,
nrow_test = nrow(processed_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing( # optimizing function to accelerate the model
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[2:145]
tuning_sigma = lr.para[146]
tuning_pred = lr.para[147:446]
tuning_pred[1:9]
tuning = data.frame(tuning_pred, tuning_y)
cor_table = round(cor(tuning, use = "complete.obs"), 5) # to see the performence of model
cor_table
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_test,
nrow_test = nrow(processed_x_test))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
beta_list = lr.para[2:145]
ans_pred = lr.para[147:1146]
ans_pred[1:18]
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_test,
nrow_test = nrow(processed_x_test))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
beta_list = lr.para[2:145]
ans_pred = lr.para[147:1146]
ans_pred[1:18]
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_test,
nrow_test = nrow(processed_x_test))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
beta_list = lr.para[2:145]
ans_pred = lr.para[147:1146]
ans_pred[1:18]
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_test,
nrow_test = nrow(processed_x_test))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
beta_list = lr.para[2:145]
ans_pred = lr.para[147:1146]
ans_pred[1:18]
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_test,
nrow_test = nrow(processed_x_test))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
beta_list = lr.para[2:145]
ans_pred = lr.para[147:1146]
ans_pred[1:18]
ans_pred = data.frame(ans_pred)
colnames(ans_pred) = c("y")
rownames(ans_pred) = c()
ans_pred
sub_data = read.csv(file = 'test.csv')[1]
sub_data = cbind(sub_data, ans_pred)
write.csv(sub_data,"test_sub.csv", row.names = FALSE)
