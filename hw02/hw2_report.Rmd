---
title: "MA_Hw_02"
output:
  html_notebook:
    toc: yes
    toc_float: yes
---
  
  
# Import libraries
The following libraries is what I've used in my code

```{r}
#suppressMessages function to load libraries siliently
suppressMessages(library(plyr))
suppressMessages(library(rethinking))
suppressMessages(library(rstan))
suppressMessages(library(tidyverse))
suppressMessages(library(ggplot2))
suppressMessages(library(gridExtra))
suppressMessages(library(caret))
```

# Read the data

I split the train data into two parts, which are fold_train_x and unfold_train_x.  
**The fold_train_x**: the columns of categorical data that haven't been one-hot encoded.  
**The unfold_train_x**: contains those having been one-hot encoded.  
 
I combine test and train data together, so we won't get "inconsistence" in columns, when we do the feature engineering.  
**The fold_all_data**: fold column in train and test data.  
**The unfold_all_data**: unfold column in train and test data.

```{r}
all_train_data = read.csv(file = 'train.csv')
test_data = read.csv(file = 'test.csv')

train_y = all_train_data["y"] ## take out the y column
train_x = all_train_data[ , (names(all_train_data)!="y")]

fold_train_x = train_x[2:9]
unfold_train_x = train_x[10:length(train_x)]

fold_test_data = test_data[2:9]
unfold_test_data = test_data[10:length(test_data)]

fold_all_data = rbind(fold_train_x, fold_test_data)
unfold_all_data = rbind(unfold_train_x, unfold_test_data)
```

# EDA

### See columns in fold_train_x
**1. The relationship between X0, X1 and y columns**

```{r}
df_to_plot = cbind(fold_train_x, train_y)

pic1 = df_to_plot %>% 
  ggplot(aes(x=reorder(factor(X0), y), y = y))+ 
  stat_summary(fun = "mean", geom = "bar")

pic2 = df_to_plot %>% 
  ggplot(aes(x=reorder(factor(X1), y), y = y))+ 
  stat_summary(fun = "mean", geom = "bar")


grid.arrange(pic1, pic2, ncol=2)
```

**2. The relationship between X2, X3 and y columns**

```{r}
pic1 = df_to_plot %>% 
  ggplot(aes(x=reorder(factor(X2), y), y = y))+ 
  stat_summary(fun = "mean", geom = "bar")

pic2 = df_to_plot %>% 
  ggplot(aes(x=reorder(factor(X3), y), y = y))+ 
  stat_summary(fun = "mean", geom = "bar")

grid.arrange(pic1, pic2, ncol=2)
```

**3. The relationship between X4, X5 and y columns**

```{r}
pic1 = df_to_plot %>% 
  ggplot(aes(x=reorder(factor(X4), y), y = y))+ 
  stat_summary(fun = "mean", geom = "bar")

pic2 = df_to_plot %>% 
  ggplot(aes(x=reorder(factor(X5), y), y = y))+ 
  stat_summary(fun = "mean", geom = "bar")

grid.arrange(pic1, pic2, ncol=2)
```

**4. The relationship between X6, X8 and y columns**

```{r}
pic1 = df_to_plot %>% 
  ggplot(aes(x=reorder(factor(X6), y), y = y))+ 
  stat_summary(fun = "mean", geom = "bar")

pic2 = df_to_plot %>% 
  ggplot(aes(x=reorder(factor(X8), y), y = y))+ 
  stat_summary(fun = "mean", geom = "bar")

grid.arrange(pic1, pic2, ncol=2)
```

# Feature Engineering & Data Processing

### 1. For columns "X3", "X4", "X6", "X8"
I drop them, because we can see that different categories in those columns doesn't cause too much difference in y.

```{r}
drops = c("X3", "X4", "X6", "X8")
selected_fold_all_data = fold_all_data[ , !(names(fold_all_data) %in% drops)] # drop the unneed columns
selected_fold_all_data
```

### 2. For column "X5"
I replace all the categories in "X5", except ("u", "x", "h", "g", "f"), because others categories in this column doesn't cause too much difference in y.

```{r}
special_cate = c("u", "x", "h", "g", "f")

levels(selected_fold_all_data$X5) = c(levels(selected_fold_all_data$X5), "new") 
selected_fold_all_data$X5[! selected_fold_all_data$X5 %in% special_cate ] = "new" ## replace the categories

selected_fold_all_data = droplevels(selected_fold_all_data)  ## drop the levels which aren't used

selected_fold_all_data
```

### 3. one-hot encode the fold data

```{r}
dummies = dummyVars(~ ., data = selected_fold_all_data) ## function to one-hot encode
onehot_fold_all_data = data.frame(predict(dummies, newdata = selected_fold_all_data))
onehot_fold_all_data
```

### 4. Split data into tuning, training and test parts

```{r}
#split all data to three parts, and combine the onehot_fold_all_data and unfold_all_data
processed_x_tuning = cbind(onehot_fold_all_data[1:300,], unfold_all_data[1:300,])
processed_x_train = cbind(onehot_fold_all_data[301:3209,], unfold_all_data[301:3209,])
processed_x_test = cbind(onehot_fold_all_data[3210:4209,], unfold_all_data[3210:4209,])
```

### 5. Drop columns of which variance is 0
The nearZeroVar function find out the column of which variance is 0, which means almost all the rows are the same in that column here.  
And because that columns are almost all 0 or 1, so we could drop it.

```{r}
all_processed_x = rbind(processed_x_tuning, processed_x_train)
all_processed_x = rbind(all_processed_x, processed_x_test)
nzv = nearZeroVar(all_processed_x) # this function is to find out the column of which variance is 0

processed_x_tuning = processed_x_tuning[, -nzv]
processed_x_train = processed_x_train[, -nzv]
processed_x_test = processed_x_test[, -nzv]

tuning_y = as.vector(t(train_y))[1:300] # The tuning y
train_y = as.vector(t(train_y))[301:3209] # The training y

```

# Model Part

### 1. The stan model
I use matrix to save my train_x, instead of vector which we seen in the tutorial, because there's too many dimension of feature.
```{r}
lr.model = "
data{
    int<lower=0> nrow;
    int<lower=0> ncol;
    matrix[nrow, ncol] train_x; //use matirx rather than vector
    vector[nrow] train_y;
    int<lower=0> nrow_test;
    matrix[nrow_test, ncol] test;
}
parameters{
    real alpha;
    vector[ncol] beta;
    real<lower=0> sigma;
}
model{
    alpha ~ normal(0,5);
    beta ~ normal(0,9); 
    sigma ~ normal(0,2);
    
    train_y ~ normal(train_x * beta + alpha, sigma);
    //train_x lies afore beta, because it's a matrix multiplication
}
generated quantities{
    real y_pred[nrow_test];
    vector[nrow_test] mu;
    
    mu = alpha + test * beta;
    y_pred = normal_rng(mu, sigma); //get pred
}
"

```

### 2. The Tuning Part
I set tuning part, so that I can know how to adjust my hyper-parameters.  
Also, to be more efficient, I use "optimizing", which is a function in stan, to accelerate the model.
```{r}
lr.data = list(
              train_x = processed_x_train, 
              train_y = train_y, 
              
              nrow = nrow(processed_x_train), 
              ncol = ncol(processed_x_train),
              
              test = processed_x_tuning, 
              nrow_test = nrow(processed_x_tuning))

stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing( # optimizing function to accelerate the model
                stan_m,
                data = lr.data,
                hessian = TRUE)
```

### 3. peek on tuning outcome
I check the prediction of tuning data, and use correlation function to see how well the model does.

```{r}
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[2:145]
tuning_sigma = lr.para[146]
tuning_pred = lr.para[147:446]
tuning_pred[1:9]

tuning = data.frame(tuning_pred, tuning_y)
cor_table = round(cor(tuning, use = "complete.obs"), 5) # to see the performence of model
cor_table
```

### 4. Finally start prediction 

```{r}
lr.data = list(
              train_x = processed_x_train, 
              train_y = train_y, 
              
              nrow = nrow(processed_x_train), 
              ncol = ncol(processed_x_train),
              
              test = processed_x_test, 
              nrow_test = nrow(processed_x_test))

stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
                stan_m,
                data = lr.data,
                hessian = TRUE)
```

### 5. Give it a look

```{r}
lr.para = lr.fit$par
beta_list = lr.para[2:145]
ans_pred = lr.para[147:1146]
ans_pred[1:18]
```

# Output Part

Make some adjustment to the outcome in order to export to csv 
```{r}
ans_pred = data.frame(ans_pred)
colnames(ans_pred) = c("y")
rownames(ans_pred) = c()
ans_pred
```

```{r}
sub_data = read.csv(file = 'test.csv')[1]
sub_data = cbind(sub_data, ans_pred)
write.csv(sub_data,"test_sub.csv", row.names = FALSE)
```

