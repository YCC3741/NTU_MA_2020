length(ans_pred)
ans_pred = data.frame(ans_pred)
colnames(ans_pred) = c("Stage1.Output.Measurement0.U.Actual")
rownames(ans_pred) = c()
test_id = data.frame(test_id)
colnames(test_id) = c("ID")
rownames(test_id) = c()
sub_data = cbind(test_id, ans_pred)
sub_data
write.csv(sub_data,"test_sub_model_1.csv", row.names = FALSE)
all_data_to_pca = rbind(processed_x_tuning, processed_x_train, processed_x_test)
# perform pca
res_pca = prcomp(all_data_to_pca)
pca_features = predict(res_pca, newdata = all_data_to_pca)
# proportion of explained variance
importance_pca <- summary(res_pca)$importance
barplot(sort(importance_pca[2, importance_pca[2, ] > 0.002], decreasing = FALSE), horiz = TRUE, xlim=c(0,0.14),
las=1, cex.names=0.6, main="Explained Variance by Principal Component", xlab="Proportion of explained variance")
colnames(pca_features)
selectcol_num = 30
pca_x_tuning = pca_features[1:991, 1:selectcol_num]
pca_x_train = pca_features[992:nrow(train_process), 1:selectcol_num]
pca_x_test = pca_features[(nrow(train_process)+1):nrow(pca_features), 1:selectcol_num]
dim(pca_x_tuning)
dim(pca_x_train)
dim(pca_x_test)
lr.data = list(
train_x = pca_x_train,
train_y = train_y,
nrow = nrow(pca_x_train),
ncol = ncol(pca_x_train),
test = pca_x_tuning,
nrow_test = nrow(pca_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing( # optimizing function to accelerate the model
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[ 2 : (2+selectcol_num-1) ]
tuning_sigma = lr.para[ 2+selectcol_num ]
tuning_pred = lr.para[ (2+selectcol_num+1) : ((2+selectcol_num+1) + 991 - 1) ] ## 991 preds
tuning_pred[1:9]
print(rmse(actual=tuning_y, predicted=tuning_pred))
lr.data = list(
train_x = pca_x_train,
train_y = train_y,
nrow = nrow(pca_x_train),
ncol = ncol(pca_x_train),
test = pca_x_test,
nrow_test = nrow(pca_x_test))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
beta_list = lr.para[ 2 : (2+selectcol_num-1) ]
ans_pred = lr.para[(2+selectcol_num+1) : ((2+selectcol_num+1) + 4088 - 1)] ## 4088 preds
ans_pred[1:9]
length(ans_pred)
ans_pred = data.frame(ans_pred)
colnames(ans_pred) = c("Stage1.Output.Measurement0.U.Actual")
rownames(ans_pred) = c()
test_id = data.frame(test_id)
colnames(test_id) = c("ID")
rownames(test_id) = c()
sub_data = cbind(test_id, ans_pred)
sub_data
write.csv(sub_data,"test_sub_model_2_PCA.csv", row.names = FALSE)
#split all data to three parts, and combine the onehot_fold_all_data and unfold_all_data
new_x_tuning1 = train_process[1:400,
(names(train_process)!="Stage1.Output.Measurement0.U.Actual")]
new_x_tuning2 = train_process[(nrow(train_process)-400+1):nrow(train_process),
(names(train_process)!="Stage1.Output.Measurement0.U.Actual")]
new_x_tuning = rbind(new_x_tuning1, new_x_tuning2)
new_x_train = train_process[401:(nrow(train_process)-400),
(names(train_process)!="Stage1.Output.Measurement0.U.Actual")]
new_tuning_y1 = train_process[1:400,
"Stage1.Output.Measurement0.U.Actual"]
new_tuning_y2 = train_process[(nrow(train_process)-400+1):nrow(train_process),
"Stage1.Output.Measurement0.U.Actual"]
new_tuning_y = rbind(new_tuning_y1, new_tuning_y2)
new_train_y = train_process[401:(nrow(train_process)-400),
"Stage1.Output.Measurement0.U.Actual"]
new_tuning_y = as.vector(t(new_tuning_y)) # The tuning y
new_train_y = as.vector(t(new_train_y)) # The training y
new_x_test = test_x
dim(new_x_tuning)
dim(new_x_train)
length(new_tuning_y)
length(new_train_y)
dim(new_x_test)
lr.data = list(
train_x = new_x_train,
train_y = new_train_y,
nrow = nrow(new_x_train),
ncol = ncol(new_x_train),
test = new_x_tuning,
nrow_test = nrow(new_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing( # optimizing function to accelerate the model
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
new_tuning_beta_list = lr.para[2:36]
new_tuning_pred = lr.para[38:(38+800-1)] ## 800 preds
rmse(actual=new_tuning_y, predicted=new_tuning_pred)
lr.data = list(
train_x = new_x_train,
train_y = new_train_y,
nrow = nrow(new_x_train),
ncol = ncol(new_x_train),
test = processed_x_test,
nrow_test = nrow(processed_x_test))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
beta_list = lr.para[ 2 : 36 ]
ans_pred = lr.para[38 : (38+4088-1)] ## 4088 preds
ans_pred[1:9]
ans_pred[(length(ans_pred)-4):length(ans_pred)]
length(ans_pred)
ans_pred = data.frame(ans_pred)
colnames(ans_pred) = c("Stage1.Output.Measurement0.U.Actual")
rownames(ans_pred) = c()
test_id = data.frame(test_id)
colnames(test_id) = c("ID")
rownames(test_id) = c()
sub_data = cbind(test_id, ans_pred)
sub_data
write.csv(sub_data,"test_sub_model_3_AnotherTuning.csv", row.names = FALSE)
all_x_train = rbind(processed_x_tuning, processed_x_train)
all_train_y = c(tuning_y, train_y)
processed_x_test = test_x
dim(all_x_train)
length(all_train_y)
dim(processed_x_test)
lr.data = list(
train_x = all_x_train,
train_y = all_train_y,
nrow = nrow(all_x_train),
ncol = ncol(all_x_train),
test = processed_x_test,
nrow_test = nrow(processed_x_test))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
beta_list = lr.para[ 2 : 36 ]
ans_pred = lr.para[38 : (38+4088-1)] ## 4088 preds
beta_list
ans_pred[1:9]
ans_pred[(length(ans_pred)-4):length(ans_pred)]
length(ans_pred)
ans_pred = data.frame(ans_pred)
colnames(ans_pred) = c("Stage1.Output.Measurement0.U.Actual")
rownames(ans_pred) = c()
test_id = data.frame(test_id)
colnames(test_id) = c("ID")
rownames(test_id) = c()
sub_data = cbind(test_id, ans_pred)
sub_data
write.csv(sub_data,"test_sub_model_4_AllData.csv", row.names = FALSE)
lr.data = list(
train_x = all_x_train,
train_y = all_train_y,
nrow = nrow(all_x_train),
ncol = ncol(all_x_train),
test = processed_x_test,
nrow_test = nrow(processed_x_test))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
#suppressMessages function to load libraries siliently
suppressMessages(library(plyr))
suppressMessages(library(rethinking))
suppressMessages(library(rstan))
suppressMessages(library(tidyverse))
suppressMessages(library(ggplot2))
suppressMessages(library(gridExtra))
suppressMessages(library(caret))
suppressMessages(library(Metrics))
suppressMessages(library(MLmetrics))
train_data = read.csv(file = 'train.csv')
train_x = train_data[, names(train_data) != "Stage1.Output.Measurement0.U.Actual"]
train_y = train_data["Stage1.Output.Measurement0.U.Actual"]
test_data = read.csv(file = 'test.csv')
test_id = test_data[,"ID"]
test_x = test_data [ , (names(test_data )!="ID")]
dim(train_x)
dim(train_y)
train_process = cbind(train_x, train_y)
ggplot()+
geom_histogram(data = train_process, aes(Stage1.Output.Measurement0.U.Actual), bins = 10)
ggplot()+
geom_point(data = train_process, aes(x = 1:nrow(train_process),
y = sort(Stage1.Output.Measurement0.U.Actual)))
train_process = train_process[-which(train_process$Stage1.Output.Measurement0.U.Actual<10),]
train_process = train_process[-which(train_process$Stage1.Output.Measurement0.U.Actual>15),]
train_process["time_stamp"]
test_x["time_stamp"]
newtime = c()
for(i in 1:nrow(train_process["time_stamp"])){
time =  gsub("[/: ]", "" , train_process[i,"time_stamp"], perl=TRUE)
time = substr(time, nchar(time)-3, nchar(time))
newtime = c(newtime, time)
}
newtime = as.numeric(newtime)
newtime = as.data.frame(newtime)
colnames(newtime) = "time_stamp"
train_process["time_stamp"] = newtime
train_process["time_stamp"]
newtime = c()
for(i in 1:nrow(test_x["time_stamp"])){
time =  gsub("[/: ]", "" , test_x[i,"time_stamp"], perl=TRUE)
time = substr(time, nchar(time)-5, nchar(time)-2)
newtime = c(newtime, time)
}
newtime = as.numeric(newtime)
newtime = as.data.frame(newtime) - (newtime[1] - train_process[1, "time_stamp"])
colnames(newtime) = "time_stamp"
test_x["time_stamp"] = newtime
test_x["time_stamp"]
ggplot()+
geom_point(data = train_process, aes(x = time_stamp,
y = sort(Stage1.Output.Measurement0.U.Actual)))
colmeans = colMeans(train_process)
colstds = sapply(train_process, sd, na.rm = TRUE)
for ( i in 1:(length(colmeans)-1) ){
train_process[,i] = train_process[,i] - colmeans[i]
train_process[,i] = train_process[,i] / colstds[i]
}
train_process
for ( i in 1:(length(colmeans)-1) ){
test_x[,i] = test_x[,i] - colmeans[i]
test_x[,i] = test_x[,i] / colstds[i]
}
test_x
df_to_draw = train_process[2:(length(train_process)-1)]
colNames = names(df_to_draw)
for(col in colNames){
plot = df_to_draw %>%
ggplot(aes_string(x=col)) +
geom_histogram(bins = 50)
print(plot)
}
linecomb = findLinearCombos(train_process)
linecomb
train_process = train_process[-linecomb$remove]
test_x = test_x[-linecomb$remove]
findLinearCombos(train_process)
lr.model = "
data{
int<lower=0> nrow;
int<lower=0> ncol;
matrix[nrow, ncol] train_x; //use matirx rather than vector
vector[nrow] train_y;
int<lower=0> nrow_test;
matrix[nrow_test, ncol] test;
}
parameters{
real alpha;
vector[ncol] beta;
real<lower=0> sigma;
}
model{
alpha ~ normal(0,10);
beta ~ normal(0,5);
sigma ~ lognormal(0,2);
train_y ~ normal(train_x * beta + alpha, sigma);
//train_x lies afore beta, because it's a matrix multiplication
}
generated quantities{
real y_pred[nrow_test];
vector[nrow_test] mu;
mu = alpha + test * beta;
y_pred = normal_rng(mu, sigma); //get pred
}
"
#split all data to three parts, and combine the onehot_fold_all_data and unfold_all_data
processed_x_tuning = train_process[1:991,
(names(train_process)!="Stage1.Output.Measurement0.U.Actual")]
processed_x_train = train_process[992:nrow(train_process),
(names(train_process)!="Stage1.Output.Measurement0.U.Actual")]
tuning_y = train_process[1:991,
"Stage1.Output.Measurement0.U.Actual"]
train_y = train_process[992:nrow(train_process),
"Stage1.Output.Measurement0.U.Actual"]
tuning_y = as.vector(t(tuning_y)) # The tuning y
train_y = as.vector(t(train_y)) # The training y
processed_x_test = test_x
dim(processed_x_tuning)
dim(processed_x_train)
length(tuning_y)
length(train_y)
dim(processed_x_test)
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_tuning,
nrow_test = nrow(processed_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing( # optimizing function to accelerate the model
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[2:36]
tuning_pred = lr.para[38:(38+991-1)] ## 991 preds
rmse(actual=tuning_y, predicted=tuning_pred)
lr.data = list(
train_x = processed_x_train,
train_y = train_y,
nrow = nrow(processed_x_train),
ncol = ncol(processed_x_train),
test = processed_x_test,
nrow_test = nrow(processed_x_test))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
beta_list = lr.para[ 2 : 36 ]
ans_pred = lr.para[38 : (38+4088-1)] ## 4088 preds
beta_list
ans_pred[1:9]
ans_pred[(length(ans_pred)-4):length(ans_pred)]
length(ans_pred)
ans_pred = data.frame(ans_pred)
colnames(ans_pred) = c("Stage1.Output.Measurement0.U.Actual")
rownames(ans_pred) = c()
test_id = data.frame(test_id)
colnames(test_id) = c("ID")
rownames(test_id) = c()
sub_data = cbind(test_id, ans_pred)
sub_data
write.csv(sub_data,"test_sub_model_1.csv", row.names = FALSE)
all_data_to_pca = rbind(processed_x_tuning, processed_x_train, processed_x_test)
# perform pca
res_pca = prcomp(all_data_to_pca)
pca_features = predict(res_pca, newdata = all_data_to_pca)
# proportion of explained variance
importance_pca <- summary(res_pca)$importance
barplot(sort(importance_pca[2, importance_pca[2, ] > 0.002], decreasing = FALSE), horiz = TRUE, xlim=c(0,0.14),
las=1, cex.names=0.6, main="Explained Variance by Principal Component", xlab="Proportion of explained variance")
colnames(pca_features)
selectcol_num = 30
pca_x_tuning = pca_features[1:991, 1:selectcol_num]
pca_x_train = pca_features[992:nrow(train_process), 1:selectcol_num]
pca_x_test = pca_features[(nrow(train_process)+1):nrow(pca_features), 1:selectcol_num]
dim(pca_x_tuning)
dim(pca_x_train)
dim(pca_x_test)
lr.data = list(
train_x = pca_x_train,
train_y = train_y,
nrow = nrow(pca_x_train),
ncol = ncol(pca_x_train),
test = pca_x_tuning,
nrow_test = nrow(pca_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing( # optimizing function to accelerate the model
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
tuning_alpha = lr.para[1]
tuning_beta_list = lr.para[ 2 : (2+selectcol_num-1) ]
tuning_sigma = lr.para[ 2+selectcol_num ]
tuning_pred = lr.para[ (2+selectcol_num+1) : ((2+selectcol_num+1) + 991 - 1) ] ## 991 preds
tuning_pred[1:9]
print(rmse(actual=tuning_y, predicted=tuning_pred))
lr.data = list(
train_x = pca_x_train,
train_y = train_y,
nrow = nrow(pca_x_train),
ncol = ncol(pca_x_train),
test = pca_x_test,
nrow_test = nrow(pca_x_test))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
beta_list = lr.para[ 2 : (2+selectcol_num-1) ]
ans_pred = lr.para[(2+selectcol_num+1) : ((2+selectcol_num+1) + 4088 - 1)] ## 4088 preds
ans_pred[1:9]
length(ans_pred)
ans_pred = data.frame(ans_pred)
colnames(ans_pred) = c("Stage1.Output.Measurement0.U.Actual")
rownames(ans_pred) = c()
test_id = data.frame(test_id)
colnames(test_id) = c("ID")
rownames(test_id) = c()
sub_data = cbind(test_id, ans_pred)
sub_data
write.csv(sub_data,"test_sub_model_2_PCA.csv", row.names = FALSE)
#split all data to three parts, and combine the onehot_fold_all_data and unfold_all_data
new_x_tuning1 = train_process[1:400,
(names(train_process)!="Stage1.Output.Measurement0.U.Actual")]
new_x_tuning2 = train_process[(nrow(train_process)-400+1):nrow(train_process),
(names(train_process)!="Stage1.Output.Measurement0.U.Actual")]
new_x_tuning = rbind(new_x_tuning1, new_x_tuning2)
new_x_train = train_process[401:(nrow(train_process)-400),
(names(train_process)!="Stage1.Output.Measurement0.U.Actual")]
new_tuning_y1 = train_process[1:400,
"Stage1.Output.Measurement0.U.Actual"]
new_tuning_y2 = train_process[(nrow(train_process)-400+1):nrow(train_process),
"Stage1.Output.Measurement0.U.Actual"]
new_tuning_y = rbind(new_tuning_y1, new_tuning_y2)
new_train_y = train_process[401:(nrow(train_process)-400),
"Stage1.Output.Measurement0.U.Actual"]
new_tuning_y = as.vector(t(new_tuning_y)) # The tuning y
new_train_y = as.vector(t(new_train_y)) # The training y
new_x_test = test_x
dim(new_x_tuning)
dim(new_x_train)
length(new_tuning_y)
length(new_train_y)
dim(new_x_test)
lr.data = list(
train_x = new_x_train,
train_y = new_train_y,
nrow = nrow(new_x_train),
ncol = ncol(new_x_train),
test = new_x_tuning,
nrow_test = nrow(new_x_tuning))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing( # optimizing function to accelerate the model
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
new_tuning_beta_list = lr.para[2:36]
new_tuning_pred = lr.para[38:(38+800-1)] ## 800 preds
rmse(actual=new_tuning_y, predicted=new_tuning_pred)
lr.data = list(
train_x = new_x_train,
train_y = new_train_y,
nrow = nrow(new_x_train),
ncol = ncol(new_x_train),
test = processed_x_test,
nrow_test = nrow(processed_x_test))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
beta_list = lr.para[ 2 : 36 ]
ans_pred = lr.para[38 : (38+4088-1)] ## 4088 preds
ans_pred[1:9]
ans_pred[(length(ans_pred)-4):length(ans_pred)]
length(ans_pred)
ans_pred = data.frame(ans_pred)
colnames(ans_pred) = c("Stage1.Output.Measurement0.U.Actual")
rownames(ans_pred) = c()
test_id = data.frame(test_id)
colnames(test_id) = c("ID")
rownames(test_id) = c()
sub_data = cbind(test_id, ans_pred)
sub_data
write.csv(sub_data,"test_sub_model_3_AnotherTuning.csv", row.names = FALSE)
all_x_train = rbind(processed_x_tuning, processed_x_train)
all_train_y = c(tuning_y, train_y)
processed_x_test = test_x
dim(all_x_train)
length(all_train_y)
dim(processed_x_test)
lr.data = list(
train_x = all_x_train,
train_y = all_train_y,
nrow = nrow(all_x_train),
ncol = ncol(all_x_train),
test = processed_x_test,
nrow_test = nrow(processed_x_test))
stan_m = stan_model(model_code = lr.model)
lr.fit = optimizing(
stan_m,
data = lr.data,
hessian = TRUE)
lr.para = lr.fit$par
beta_list = lr.para[ 2 : 36 ]
ans_pred = lr.para[38 : (38+4088-1)] ## 4088 preds
beta_list
ans_pred[1:9]
ans_pred[(length(ans_pred)-4):length(ans_pred)]
length(ans_pred)
ans_pred = data.frame(ans_pred)
colnames(ans_pred) = c("Stage1.Output.Measurement0.U.Actual")
rownames(ans_pred) = c()
test_id = data.frame(test_id)
colnames(test_id) = c("ID")
rownames(test_id) = c()
sub_data = cbind(test_id, ans_pred)
sub_data
write.csv(sub_data,"test_sub_model_4_AllData.csv", row.names = FALSE)
